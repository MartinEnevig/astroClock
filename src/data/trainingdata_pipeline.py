from datetime import datetime
import numpy as np
import random
from typing import Any, Optional

class TrainingDataPipeline:
    """
    Transforms data to the format necessary to train the model.
    Pipeline takes data organized by steps. Each step is an array of shape (10, 2), where each row contains the r and theta of an object.
    Objects are ordered according to the variable objects in utils/const.py.
    For each step an object execution order is decided based on which object has the largest distance in theta to the next object.
    For each step a new nd.array of shape (5, 12) is created. This array is created by looping through the objects in the step by order of excecution
    and then creating a row for each object. This row contains the object's current position in r and theta, the positions of the nearest four objects, 
    and it's target position. 

    These new arrays are stacked, so we end up with a 2d array of shape (n, 12). Each row in this array represents a single object to be moved in the clock.
    For training purposes any initial collissions are removed.

    Finally new artificial samples are generated by adding a random float in the interval [-datapoint*0.05, datapoint*0.05] with conditions ensuring that
    the new positions does not have r greater than c.BOARD_EDGE_RADIUS and are not moved to create an initial collision with the current object.

    Output: ndarray with training data 
    """
    def __init__(self, filepath: str = "./src/data/data1.npy"):
        with open(filepath, "rb") as train:
            self.data: np.ndarray = np.load(train)

    def __call__(self, batching: bool, batch_start: Optional[int], batch_end: Optional[int],  augment: bool=True) -> np.ndarray:
        
        if batching:
            self.training_data = self.data[batch_start: batch_end]
        else:
            self.training_data = self.data

        data = self.generate_initial_training_data(self.training_data)
        
        data_with_targets = self._add_targets(data)

        if augment:
            augmented_data_with_targets = self.augment_data(data_with_targets)
            return augmented_data_with_targets

        return data_with_targets
    
    def generate_initial_training_data(self, data: np.ndarray) -> np.ndarray:
        for step in range(data.shape[0]-1):
            order = self.order_objects(data[step])
            ordered_data = data[step][order]
            
            for idx, org_idx in enumerate(order):
                flattened_positions = self._get_flattened_positions(position_data=ordered_data, starting_no=idx, org_no=org_idx, step=step)
                
                if step == 0 and idx == 0:
                    positions = flattened_positions
                else:
                    positions = np.vstack((positions, flattened_positions))
            if step % 100 == 0:
                print(f"step no. {step} out of {data.shape[0]}")

        return positions            

    def order_objects(self, positions: np.ndarray) -> list:
        """
        Orders objects by theta and determines the object to be moved first in
        the current round.
        Arguments: Positions. An np.ndarray of shape (10, 2) holding the positions of
        each object in the current round.
        Returns: An np.ndarray of object numbers in order of movement in the current round.

        First an index is added to keep track of which object has which position.
        Then the positions are sorted by theta - column 2 in the indexed positions.
        Finally we measure the distance between the thetas of each object and the object 
        closest in front of it. The object with the largest distance measured in theta
        to the object on front of it is the starting object.

        Measurements are done with positions rotated, so the object being measured has
        theta zero. 
        """
        
        index = np.arange(0, 10).reshape(-1, 1).reshape(-1, 1)
        indexed_positions = np.hstack((index, positions))
        sorted_positions = indexed_positions[indexed_positions[:, 2].argsort()[::-1]]

        starting_object = self._get_starting_object(sorted_positions)
        
        order_of_excecution = np.roll(sorted_positions, -starting_object, axis=0)[:, 0]

        return list(order_of_excecution.astype(int))

    @classmethod
    def augment_data(cls, data) -> np.ndarray:
        for i in range(data.shape[0]):
            augment = cls._augment(data[i])
            if i == 0:
                augmented_data = augment
            else:
                augmented_data = np.vstack((augmented_data, augment))
        return augmented_data
    
    @staticmethod
    def _add_targets(data: np.ndarray) -> np.ndarray:
        target_r = data[:, 0] - data[:, 10]
        target_theta = data[:, 11]

        target_positions = np.hstack((target_r.reshape(-1, 1).reshape(-1, 1), target_theta.reshape(-1, 1).reshape(-1, 1)))

        return np.hstack((data, target_positions))
    
    @staticmethod
    def _rotate_data(positions: np.ndarray) -> np.ndarray:
        theta = positions[0, 1]
        rotated_objects = positions[:, 1] - theta
        positions[:, 1] = np.where(rotated_objects >= 0, rotated_objects, rotated_objects + 2*np.pi) 
        return positions
    
    def _rotate_objects(self, positions: np.ndarray, current_object_index: int) -> np.ndarray:
        """
        Rotates objects so that a given current_object is at theta zero. 
        Args:
        Positions. An np.ndarray of positions.
        current_object_index. The index value of the object chosen as current_object,
        for the given rotation.
        """
        current_object_theta = positions[current_object_index, 2]
        rotated_positions = positions[:, 2] - current_object_theta
        positions[:, 2] = np.where(rotated_positions >= 0, rotated_positions, rotated_positions + 2*np.pi) 
        
        return positions

    def _get_starting_object(self, positions: np.ndarray) -> int:
        """
        Args:
        Positions. An np.ndarray with the positions where we want difference between
        a positions theta coordinate and the next position's theta to be calculated.
        
        Difference is calculated by by creating a new array, where the order of the 
        positions is shifted by one using np.roll. The original array's theta column is
        then subtracted from the new array's theta column, giving the difference. 
        """
        positions_theta = self._rotate_objects(positions=positions, current_object_index=9)[:, 2]
        rolled_positions_theta = np.roll(positions_theta, 1)
        rolled_positions_theta[0] = np.pi*2
        differences = rolled_positions_theta - positions_theta

        return np.argmax(differences)

    def _get_flattened_positions(self, position_data: np.ndarray, step: int, starting_no: int,  org_no: int) -> np.ndarray:
        data_with_current_object_at_zero = np.roll(position_data, -starting_no, axis=0) 
        current_object_zero_reverse_order = np.roll(np.flipud(data_with_current_object_at_zero), 1, axis=0)
        target_position = self._find_target_position(step=step, order_no=org_no)
        ordered_data_with_target = np.vstack((current_object_zero_reverse_order, target_position))
        rotated_data = self._rotate_data(positions=ordered_data_with_target)

        flattened_array = self._populate_flattened_array(rotated_data)
        return flattened_array


    @classmethod
    def _get_positions_without_collision(cls, data: np.ndarray) -> list:
        """
        Some datapoints have an initial collision. This means that the starting position of the current object is colliding
        with another object. The aim of the neural net is to avoid this, so these situations should not be included in the training set.
        This is achieved by looping thorught the positions in order of proximity to the current object and checking if there is a collision 
        with the current object's starting position. If this is not the case the object is added to a list of position indeces used to select
        the four objects to be included in the training set. If it is the case the object is skipped.
        """
        positions = []
        current_position = data[0]
        for i in range(1, 10):
            euclidian_distance = cls._calc_euclidian_distance(current_position, data[i])
            if euclidian_distance > 120 and len(positions) < 4:
                positions.append(i)
        return positions
    
    @classmethod
    def _populate_flattened_array(cls, position_data: np.ndarray) -> np.ndarray:
        
        flattened_positions = np.empty(shape=(1, 12), dtype=np.float32)
        flattened_positions[0, 0] = position_data[0, 0]
        flattened_positions[0, 1] = position_data[0, 1]

        no_collision = cls._get_positions_without_collision(position_data)

        flattened_positions[0, 2] = position_data[no_collision[0], 0]
        flattened_positions[0, 3] = position_data[no_collision[0], 1]

        flattened_positions[0, 4] = position_data[no_collision[1], 0]
        flattened_positions[0, 5] = position_data[no_collision[1], 1]

        flattened_positions[0, 6] = position_data[no_collision[2], 0]
        flattened_positions[0, 7] = position_data[no_collision[2], 1]

        flattened_positions[0, 8] = position_data[no_collision[3], 0]
        flattened_positions[0, 9] = position_data[no_collision[3], 1]

        flattened_positions[0, 10] = position_data[10, 0]
        flattened_positions[0, 11] = position_data[10, 1]

        return flattened_positions
    
    def _find_target_position(self, step: int, order_no: int) -> np.ndarray:
        return self.training_data[step+1][order_no]

    @classmethod
    def _calc_euclidian_distance(cls, pos_1: np.ndarray, pos_2: np.ndarray) -> np.float32:
        pos_1_cartesian = cls._to_cartesian(pos_1)
        pos_2_cartesian = cls._to_cartesian(pos_2)

        return np.linalg.norm(pos_2_cartesian - pos_1_cartesian)
    
    @staticmethod
    def _to_cartesian(pos: np.ndarray) -> np.ndarray:
        posXY = np.empty(2, dtype=np.float32)
        posXY[0], posXY[1] = np.sin(pos[1])*pos[0], np.cos(pos[1])*pos[0]
        return posXY
    
    @staticmethod
    def splitter(data: np.ndarray) -> tuple:
        train, val_test = train_test_split(data, test_size=0.2, random_state=42)
        val, test = train_test_split(val_test, test_size=0.5, random_state=42)

        return train, val, test

    @classmethod
    def _augment(cls, row) -> np.ndarray:
        row_1 = [cls._auger(ind, val) for ind, val in enumerate(row)]
        row_2 = [cls._auger(ind, val) for ind, val in enumerate(row)]
        row_3 = [cls._auger(ind, val) for ind, val in enumerate(row)]
        row_4 = [cls._auger(ind, val) for ind, val in enumerate(row)]
        row_5 = [cls._auger(ind, val) for ind, val in enumerate(row)]

        return np.array([row, row_1, row_2, row_3, row_4, row_5])
    
    @staticmethod
    def _auger(ind, val) -> np.float32:
        new_val = val + random.uniform(-val*0.05, val*0.05)
        
        if new_val == 0.0:
            new_val += random.uniform(-0.05, 0.05)
        if ind % 2 != 0 and new_val > np.pi*2:
            new_val = val + random.uniform(-val*0.05, 0)
        if new_val > 1340.0:
            new_val = 1340.0
        return np.float32(new_val)

pipe = TrainingDataPipeline()

start = datetime.now()
for batch in range(5206):
    data = pipe(batching=True, batch_start=batch*1000, batch_end=(batch+1)*1000)
    if batch == 0:
        final = data
    else:
        final = np.vstack((final, data))
    
    print(f"batch {batch} finished")
    print(f"ran for {datetime.now()-start}")
    print(f"dataset size: {final.shape}")

np.save(file="./src/data/large_train.npy", arr=final)



